{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2679,
     "status": "ok",
     "timestamp": 1740876739174,
     "user": {
      "displayName": "Francesco",
      "userId": "17757392889991151115"
     },
     "user_tz": -60
    },
    "id": "cFCI92wYdpJt",
    "outputId": "59deaabc-97eb-43ed-b740-2e10aa148256"
   },
   "outputs": [],
   "source": [
    "%pip install loguru==0.7.3 python-dotenv==1.0.1 PyYAML==6.0.2 torch==2.5.1 tqdm==4.67.1 typer==0.15.1 matplotlib==3.10.0 pyarrow==18.1.0 setuptools==75.1.0 protobuf==4.25.3 wandb==0.19.7 ultralytics==8.3.90 ray==2.43.0 albumentations==2.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h04mIHIKdUZr"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ultralytics import YOLO, settings\n",
    "import locale\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "from ray import tune\n",
    "from typing import Dict\n",
    "from ultralytics.data.dataset import YOLODataset\n",
    "from ultralytics.models.yolo.detect import DetectionTrainer\n",
    "from ultralytics.utils import colorstr, LOGGER\n",
    "import numpy as np\n",
    "\n",
    "sys.dont_write_bytecode = True\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "os.environ[\"RAY_TRAIN_V2_ENABLED\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device\n",
    "\n",
    "def get_device() -> str:\n",
    "    try:\n",
    "        return 0 if torch.cuda.is_available() else \"cpu\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting device: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb init\n",
    "\n",
    "def get_wandb_key_colab() -> str:\n",
    "    try:\n",
    "        from google.colab import userdata # type: ignore\n",
    "\n",
    "        if userdata.get(\"WANDB_API_KEY\") is not None:\n",
    "            return userdata.get(\"WANDB_API_KEY\")\n",
    "        else:\n",
    "            raise ValueError(\"No WANDB key found\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_wandb_env(path: Path) -> str:\n",
    "    try:\n",
    "        from dotenv import dotenv_values # type: ignore\n",
    "\n",
    "        \"\"\"Get W&B API key from Colab userdata or environment variable\"\"\"\n",
    "\n",
    "        path = Path(path)\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Could not find .env file at {path}\")\n",
    "\n",
    "        print(f\"Loading secrets from {path}\")\n",
    "\n",
    "        secrets = dotenv_values(path)\n",
    "        print(f\"Found keys: {list(secrets.keys())}\")\n",
    "\n",
    "        if \"WANDB_API_KEY\" not in secrets:\n",
    "            raise KeyError(f\"WANDB_API_KEY not found in {path}. Available keys: {list(secrets.keys())}\")\n",
    "\n",
    "        return secrets['WANDB_API_KEY']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_wandb_key(path: Path = \"../.env\") -> str:\n",
    "    return get_wandb_key_colab() if get_wandb_key_colab() is not None else get_wandb_env(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset, Trainer, Validator\n",
    "\n",
    "class VisDroneDataset(YOLODataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for VisDrone that merges pedestrian (0) and people (1) classes.\n",
    "    Handles class remapping at the earliest possible stage.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the merged names as a class attribute to be accessible from the trainer\n",
    "    merged_names = {\n",
    "        0: 'persona',\n",
    "        1: 'bicicletta',\n",
    "        2: 'auto',\n",
    "        3: 'furgone',\n",
    "        4: 'camion',\n",
    "        5: 'triciclo',\n",
    "        6: 'triciclo-tendato',\n",
    "        7: 'autobus',\n",
    "        8: 'motociclo'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Store original data before initialization if it exists in kwargs\n",
    "        self.original_data = kwargs.get('data', {}).copy() if 'data' in kwargs else None\n",
    "        \n",
    "        # Adjust data names before parent initialization to make verification pass\n",
    "        if self.original_data and 'names' in self.original_data:\n",
    "            # Create a temporary data object with 10 classes for verification\n",
    "            temp_data = self.original_data.copy()\n",
    "            # Ensure we have all 10 original class names for validation\n",
    "            if len(temp_data.get('names', {})) != 10:\n",
    "                temp_data['names'] = {\n",
    "                    0: 'pedestrian',\n",
    "                    1: 'people',\n",
    "                    2: 'bicycle',\n",
    "                    3: 'car',\n",
    "                    4: 'van',\n",
    "                    5: 'truck',\n",
    "                    6: 'tricycle',\n",
    "                    7: 'awning-tricycle',\n",
    "                    8: 'bus',\n",
    "                    9: 'motor'\n",
    "                }\n",
    "            # Replace data in kwargs\n",
    "            kwargs['data'] = temp_data\n",
    "        \n",
    "        # Initialize parent class with modified kwargs\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Log class mapping\n",
    "        LOGGER.info(f\"{colorstr('VisDroneDataset:')} Using merged classes: {self.merged_names}\")\n",
    "    \n",
    "    def get_labels(self):\n",
    "        \"\"\"\n",
    "        Load and process labels with class remapping.\n",
    "        \"\"\"\n",
    "        # Get labels from parent method\n",
    "        labels = super().get_labels()\n",
    "        \n",
    "        # Process statistics\n",
    "        people_count = 0\n",
    "        shifted_count = 0\n",
    "        \n",
    "        # Process labels to merge classes\n",
    "        for i in range(len(labels)):\n",
    "            cls = labels[i]['cls']\n",
    "            \n",
    "            if len(cls) > 0:\n",
    "                # Count 'people' instances\n",
    "                people_mask = cls == 1\n",
    "                people_count += np.sum(people_mask)\n",
    "                \n",
    "                # Merge class 1 (people) into class 0 (pedestrian -> person)\n",
    "                cls[people_mask] = 0\n",
    "                \n",
    "                # Shift classes > 1 down by 1\n",
    "                gt1_mask = cls > 1\n",
    "                shifted_count += np.sum(gt1_mask)\n",
    "                cls[gt1_mask] -= 1\n",
    "                \n",
    "                # Store modified labels\n",
    "                labels[i]['cls'] = cls\n",
    "        \n",
    "        # Now set correct class count and names for training\n",
    "        if hasattr(self, 'data'):\n",
    "            # Update names and class count\n",
    "            self.data['names'] = self.merged_names\n",
    "            self.data['nc'] = len(self.merged_names)\n",
    "        \n",
    "        # Log statistics\n",
    "        person_count = sum(np.sum(label['cls'] == 0) for label in labels)\n",
    "        LOGGER.info(f\"\\n{colorstr('VisDroneDataset:')} Remapped {people_count} 'people' instances to {self.merged_names[0]}\")\n",
    "        LOGGER.info(f\"{colorstr('VisDroneDataset:')} Total 'persona' instances after merge: {person_count}\")\n",
    "        LOGGER.info(f\"{colorstr('VisDroneDataset:')} Shifted {shifted_count} instances of other classes\")\n",
    "        \n",
    "        return labels\n",
    "\n",
    "class MergedClassDetectionTrainer(DetectionTrainer):\n",
    "    \"\"\"\n",
    "    Custom trainer that uses VisDroneDataset for merged class training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def build_dataset(self, img_path, mode=\"train\", batch=None):\n",
    "        \"\"\"Build custom VisDroneDataset.\"\"\"\n",
    "        return VisDroneDataset(\n",
    "            img_path=img_path,\n",
    "            imgsz=self.args.imgsz,\n",
    "            batch_size=batch or self.batch_size,\n",
    "            augment=mode == \"train\",\n",
    "            hyp=self.args,\n",
    "            rect=self.args.rect if mode == \"train\" else True,\n",
    "            cache=self.args.cache or None,\n",
    "            single_cls=self.args.single_cls,\n",
    "            stride=self.stride,\n",
    "            pad=0.0 if mode == \"train\" else 0.5,\n",
    "            prefix=colorstr(f\"{mode}: \"),\n",
    "            task=self.args.task,\n",
    "            classes=None,\n",
    "            data=self.data,\n",
    "            fraction=self.args.fraction if mode == \"train\" else 1.0,\n",
    "        )\n",
    "    \n",
    "    def set_model_attributes(self):\n",
    "        \"\"\"Update model attributes for merged classes.\"\"\"\n",
    "        # First call parent method to set standard attributes\n",
    "        super().set_model_attributes()\n",
    "        \n",
    "        # Then update model with the merged class names\n",
    "        if hasattr(self.model, 'names'):\n",
    "            # Use the merged names directly from the dataset class\n",
    "            self.model.names = VisDroneDataset.merged_names\n",
    "            self.model.nc = len(VisDroneDataset.merged_names)\n",
    "            \n",
    "            # Also update data dictionary\n",
    "            if hasattr(self, 'data'):\n",
    "                self.data['names'] = VisDroneDataset.merged_names\n",
    "                self.data['nc'] = len(VisDroneDataset.merged_names)\n",
    "\n",
    "from ultralytics.models.yolo.detect import DetectionValidator\n",
    "\n",
    "class MergedClassDetectionValidator(DetectionValidator):\n",
    "    \"\"\"\n",
    "    Custom validator that uses VisDroneDataset for validation/testing with merged classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def build_dataset(self, img_path, mode=\"val\", batch=None):\n",
    "        \"\"\"Build custom VisDroneDataset for validation.\"\"\"\n",
    "        return VisDroneDataset(\n",
    "            img_path=img_path,\n",
    "            imgsz=self.args.imgsz,\n",
    "            batch_size=batch or self.args.batch,\n",
    "            augment=False,  # no augmentation during validation\n",
    "            hyp=self.args,\n",
    "            rect=True,  # rectangular validation for better performance\n",
    "            cache=None,\n",
    "            single_cls=self.args.single_cls,\n",
    "            stride=self.stride,\n",
    "            pad=0.5,\n",
    "            prefix=colorstr(f\"{mode}: \"),\n",
    "            task=self.args.task,\n",
    "            classes=self.args.classes,\n",
    "            data=self.data,\n",
    "        )\n",
    "    \n",
    "    def set_model_attributes(self):\n",
    "        \"\"\"Update model attributes for merged classes if using a PyTorch model.\"\"\"\n",
    "        super().set_model_attributes()\n",
    "        \n",
    "        # Update model names if it's a PyTorch model (not for exported models)\n",
    "        if hasattr(self.model, 'names') and hasattr(self.model, 'model'):\n",
    "            self.model.names = VisDroneDataset.merged_names\n",
    "            if hasattr(self.data, 'names'):\n",
    "                self.data['names'] = VisDroneDataset.merged_names\n",
    "                self.data['nc'] = len(VisDroneDataset.merged_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = \"\"\"\n",
    "wandb_project: \"EyeInTheSky_merged_tuning\"\n",
    "data: \"VisDrone.yaml\"\n",
    "train:\n",
    "  model: \"yolo12n.pt\"\n",
    "  project: \"EyeInTheSky\"\n",
    "  data: \"VisDrone.yaml\"\n",
    "  optimizer: \"AdamW\"\n",
    "  task: detect\n",
    "  epochs: 3\n",
    "  batch: 8\n",
    "  workers: 4\n",
    "  seed: 42\n",
    "  plots: True\n",
    "  imgsz: 640\n",
    "  exist_ok: False\n",
    "  save: True\n",
    "  save_period: 10\n",
    "  val: True\n",
    "  # warmup_epochs: 10\n",
    "  visualize: False\n",
    "  show: False\n",
    "  single_cls: False # (bool) train multi-class data as single-class\n",
    "  rect: False # (bool) rectangular training if mode='train' or rectangular validation if mode='val'\n",
    "  cos_lr: False\n",
    "  resume: False\n",
    "  amp: True # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check\n",
    "  fraction: 1.0\n",
    "  freeze: None\n",
    "  cache: False\n",
    "val:\n",
    "  project: \"EyeInTheSky\"\n",
    "  name: \"YOLOv12-VisDrone-Validation\"\n",
    "  half: True\n",
    "  conf: 0.25\n",
    "  iou: 0.6\n",
    "  split: \"test\"\n",
    "  rect: True\n",
    "  plots: True\n",
    "  visualize: True\n",
    "tune:\n",
    "  project: \"EyeInTheSky_tuned\"\n",
    "  name: \"YOLOv12-VisDrone-Tuning\"\n",
    "  optimizer: \"AdamW\"\n",
    "  batch: 16\n",
    "  seed: 42\n",
    "  val: False\n",
    "  imgsz: 640 \n",
    "  cache: False\n",
    "  visualize: True\n",
    "  show: True\n",
    "\n",
    "\"\"\"\n",
    "config = yaml.safe_load(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "\n",
    "# config = Config.load(\"../config/config.yaml\")\n",
    "config = yaml.safe_load(config_data)\n",
    "config[\"train\"].update({\"device\" : get_device()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWOz0dWfAtIw"
   },
   "outputs": [],
   "source": [
    "# Search space\n",
    "\n",
    "search_space = {\n",
    "    \"lr0\": tune.choice([1e-4, 1e-3]),\n",
    "    \"lrf\": tune.choice([0.01, 0.1]),\n",
    "    \"momentum\": tune.choice([0.8, 0.9, 0.95]),\n",
    "    \"weight_decay\": tune.choice([0.0, 0.001]),\n",
    "    \"box\": tune.uniform(3.0, 7.0),\n",
    "    \"cls\": tune.uniform(0.5, 2.0),\n",
    "    \"dfl\": tune.uniform(3.0, 6.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_merged_classes(ray_config: Dict, train_config: Dict=None):\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \"\"\"\n",
    "    Training function for Ray Tune that uses a custom dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        ray_config (dict): Hyperparameters passed by Ray Tune.\n",
    "        train_config (dict): Fixed training configuration.\n",
    "    \"\"\"\n",
    "    # Merge fixed training config with Ray Tune hyperparameters\n",
    "    # (Hyperparameters from ray_config will override those in train_config)\n",
    "    if train_config is None:\n",
    "        train_config = {}\n",
    "    merged_config = {**train_config, **ray_config}\n",
    "    \n",
    "    model = YOLO(train_config[\"model\"], verbose=False)\n",
    "    \n",
    "    setattr(sys.modules[\"ultralytics.data.dataset\"], \"VisDroneDataset\", VisDroneDataset)\n",
    "    \n",
    "    # Train with the merged hyperparameters (only those keys that are expected by model.train should be present)\n",
    "    results = model.tune(use_ray=True, grace_period=2, trainer=MergedClassDetectionTrainer, **merged_config)\n",
    "    \n",
    "    # Return a dictionary of metrics for Ray Tune to monitor (e.g. 'fitness')\n",
    "    # metrics = {\n",
    "    #     \"precision\": getattr(results, \"precision\", 0),\n",
    "    #     \"recall\": getattr(results, \"recall\", 0),\n",
    "    #     \"mAP50-95\": getattr(results, \"mAP50_95\", 0),\n",
    "    #     \"mAP50\": getattr(results, \"mAP50\", 0),\n",
    "    # }\n",
    "    # tune.report(**metrics)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    return results\n",
    "\n",
    "def tune_with_merged_classes(search_space, train_config, **kwargs):\n",
    "    trainable_with_resources = tune.with_resources(train_with_merged_classes, {\"cpu\":8,\"gpu\":1})\n",
    "\n",
    "    # Use tune.with_parameters to \"bake in\" the fixed training configuration.\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_parameters(trainable_with_resources, train_config=train_config),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            num_samples=1,\n",
    "            max_concurrent_trials=1,  # Run one at a time to avoid OOM\n",
    "            mode=\"max\"\n",
    "        ),\n",
    "        run_config=tune.RunConfig(**kwargs)\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = get_wandb_key()\n",
    "wandb.login(key=wandb_api_key, relogin=True)\n",
    "wandb.init(\n",
    "    project=config[\"wandb_project\"],\n",
    "    name=f\"{config['model']}_VisDrone_tune\",\n",
    ")\n",
    "settings.update({\"wandb\": True})\n",
    "\n",
    "results_path = os.path.abspath(\"../reports\")\n",
    "results = tune_with_merged_classes(\n",
    "    search_space, \n",
    "    train_config=config[\"train\"],\n",
    "    storage_path=Path(results_path)\n",
    ")\n",
    "\n",
    "wandb.finish()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVdngIxr6F7R"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# source_folder = '/content/EyeInTheSky/tune'\n",
    "# destination_folder = f'/content/drive/My Drive/EyeInTheSky/tune_{timestamp}'\n",
    "\n",
    "# shutil.copytree(source_folder, destination_folder)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "12R-K-7uKtA1zhUWEL8fr8PXpVT9y4oKJ",
     "timestamp": 1740865915151
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
